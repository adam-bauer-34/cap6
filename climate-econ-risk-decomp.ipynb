{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "shaped-pledge",
   "metadata": {},
   "source": [
    "# Climate-economic risk decomposition notebook\n",
    "\n",
    "This notebook makes the figure which compares the different price paths isolating a specific damage function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "union-covering",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import datetime\n",
    "import os \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "\n",
    "from src.analysis.output_unpacker import OutputUnpacker\n",
    "from src.analysis.class_maker import make_class_instances\n",
    "from src.tools import import_csv\n",
    "\n",
    "# plotting parameters\n",
    "color_list = ['#000000', '#E69F00', '#56B4E9', '#009E73', '#F0E442', '#0072B2', '#D55E00', '#CC79A7'] * 2\n",
    "marker_list = ['o', 's', 'P', '+', 'D', 'v', '3', 'm'] * 2\n",
    "markersize = 6\n",
    "linestyle_list = ['solid', 'dashed', 'dashdot', 'dotted'] * 4\n",
    "linewidth = 2\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina' \n",
    "cdds_params={'axes.linewidth': 3,\n",
    " 'axes.axisbelow': False,\n",
    " 'axes.edgecolor': 'black',\n",
    " 'axes.facecolor': 'None',\n",
    " 'axes.grid': False,\n",
    " 'axes.labelcolor': 'black',\n",
    " 'axes.spines.right': False,\n",
    " 'axes.spines.top': False,\n",
    " 'axes.titlesize': 20,\n",
    " 'axes.labelsize': 20,\n",
    " 'axes.titlelocation': 'left',\n",
    " 'figure.facecolor': 'white',\n",
    " 'figure.figsize': (18, 10),\n",
    " 'lines.solid_capstyle': 'round',\n",
    " 'lines.linewidth': 2.5,\n",
    " 'patch.edgecolor': 'w',\n",
    " 'patch.force_edgecolor': True,\n",
    " 'text.color': 'black',\n",
    " 'legend.frameon': False,\n",
    " 'xtick.bottom': True,\n",
    " 'xtick.major.width': 3,\n",
    " 'xtick.major.size': 6,\n",
    " 'xtick.color': 'black',\n",
    " 'xtick.direction': 'out',\n",
    " 'xtick.top': False,\n",
    " 'ytick.color': 'black',\n",
    " 'ytick.direction': 'out',\n",
    " 'ytick.left': True,\n",
    " 'ytick.right': False,\n",
    " 'ytick.color' : 'black',\n",
    " 'ytick.major.width': 3, \n",
    " 'ytick.major.size': 6,\n",
    " 'axes.prop_cycle': plt.cycler(color=color_list, linestyle=linestyle_list),\n",
    " 'font.size': 16,\n",
    " 'font.family': 'serif'}\n",
    "plt.rcParams.update(cdds_params)\n",
    "\n",
    "node_times = [2020, 2030, 2060, 2100, 2150, 2200]\n",
    "x_label = 'Year'\n",
    "\n",
    "# make base filename\n",
    "today = datetime.datetime.now()\n",
    "year = str(today.year)\n",
    "day = str(today.day)\n",
    "month = str(today.month)\n",
    "\n",
    "basefile = ''.join([month, '-', day, '-', year, '-'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "under-sally",
   "metadata": {},
   "source": [
    "## Make list of runs to analyze\n",
    "\n",
    "For any run we want to appear in the final figure, the run number should go here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-parish",
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = np.arange(0, 16, 1, dtype=int)\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-pledge",
   "metadata": {},
   "source": [
    "## Make list of files of interest\n",
    "\n",
    "Here we make lists of file prefixes (i.e., whatever the `name` parameter was when the simulation was executed) and paths. We take the list of paths and prefixes and make lists of filenames, which will be passed to `OutputUnpacker` later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import BPW_research_runs.csv\n",
    "\n",
    "data_csv_file = 'research_runs'\n",
    "param_names, run_info, param_vals = import_csv(data_csv_file, delimiter=',', indices=2)\n",
    "all_run_names = np.array([run_info[i][1] for i in range(len(run_info))])\n",
    "\n",
    "# this an array of run names that are being analyzed\n",
    "run_names = all_run_names[runs]\n",
    "N_runs = len(run_names)\n",
    "\n",
    "# path list (just data directory N_runs times)\n",
    "paths = [os.getcwd()] * N_runs\n",
    "\n",
    "# make list of full file names (path + run name + suffix) to be analyzed\n",
    "output_list = [''.join([paths[file], run_names[file], \"_node_period_output.csv\"]) for file in range(N_runs)]\n",
    "picklefile_list = [''.join([paths[file], run_names[file], \"_log.pickle\"]) for file in range(N_runs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beginning-wagner",
   "metadata": {},
   "source": [
    "## Make lists of necessary model classes\n",
    "\n",
    "Make sure this matches the main file! To do this properly, the right classes with the right model parameters need to be initiated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-berry",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_list, damage_list, climate_list, emit_baseline_list = make_class_instances(runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "present-sierra",
   "metadata": {},
   "source": [
    "## Use `OutputUnpacker` object to extract values from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "proper-beach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one array of objects which correspond to the 'output' files (i.e., the files that end with\n",
    "# _node_period_output.csv) and another for the pickle files\n",
    "output_obj_list = [OutputUnpacker(output_list[file], run_names[file], 'output', \n",
    "                                    tree=tree_list[file], emit_baseline=emit_baseline_list[file],\n",
    "                                    climate=climate_list[file], damage=damage_list[file]) for file in range(N_runs)]\n",
    "\n",
    "pickle_obj_list = [OutputUnpacker(picklefile_list[file], run_names[file], 'pickle',\n",
    "                                    tree=tree_list[file], emit_baseline=emit_baseline_list[file],\n",
    "                                    climate=climate_list[file], damage=damage_list[file]) for file in range(N_runs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-bulletin",
   "metadata": {},
   "source": [
    "## Save fig?!\n",
    "\n",
    "Turn on if you want the figure saved!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-manufacturer",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_fig = True\n",
    "runs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alleged-florence",
   "metadata": {},
   "source": [
    "## Import damage scatter points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701eeefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd() + '/data/' # find current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-bonus",
   "metadata": {},
   "outputs": [],
   "source": [
    "burke_2049_ssp2 = np.genfromtxt(''.join([path, 'ssp2_2049_t_d.csv']), delimiter=',')\n",
    "burke_2049_ssp2_t, burke_2049_ssp2_d = burke_2049_ssp2.T\n",
    "\n",
    "burke_2099_ssp2 = np.genfromtxt(''.join([path, 'ssp2_2099_t_d.csv']), delimiter=',')\n",
    "burke_2099_ssp2_t, burke_2099_ssp2_d = burke_2099_ssp2.T\n",
    "\n",
    "struct_data = np.genfromtxt(''.join([path, \"IPCC_WGII_RoseDamageEstimates.csv\"]), \n",
    "                            delimiter=',', usecols=[0,1])\n",
    "struct_T, struct_d = struct_data.T\n",
    "\n",
    "hs_data = np.genfromtxt(''.join([path, \"IPCC_WGII_HowardSternerDamageEstimates.csv\"]), \n",
    "                        delimiter=',', usecols=[0,1])\n",
    "hs_T, hs_d = hs_data.T"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "preceding-realtor",
   "metadata": {},
   "source": [
    "## Do fits\n",
    "\n",
    "Basic idea: compute distributions for reach paramter, compute percentiles and means for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65af3c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmst = np.arange(0, 7, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42886e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "size = 1000\n",
    "burke_mid_b2 = np.random.normal(loc=3.09e-3, scale=4.76e-4, \n",
    "                                size=size)\n",
    "burke_mid_b1 = np.random.normal(loc=1.24e-2, scale=1.90e-3, \n",
    "                                size=size)\n",
    "\n",
    "burke_end_b2 = np.random.normal(loc=-2.33e-3, scale=4.75e-4, \n",
    "                                size=size)\n",
    "burke_end_b1 = np.random.normal(loc=7.21e-2, scale=1.47e-2, \n",
    "                                size=size)\n",
    "\n",
    "struct_b2 = np.random.normal(loc=2.3e-3, scale=8.53e-4, \n",
    "                                size=size)\n",
    "struct_b1 = np.random.normal(loc=2.05e-3, scale=7.59e-4, \n",
    "                                size=size)\n",
    "\n",
    "meta_b2 = np.random.normal(loc=6.85e-3, scale=2.43e-3, \n",
    "                                size=size)\n",
    "meta_b1 = np.random.normal(loc=2.98e-4, scale=1.06e-4, \n",
    "                                size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b224f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "burke_mid_dam = gmst * (burke_mid_b2[:, None] * gmst + burke_mid_b1[:, None])\n",
    "burke_end_dam = gmst * (burke_end_b2[:, None] * gmst + burke_end_b1[:, None])\n",
    "struct_dam = gmst * (struct_b2[:, None] * gmst + struct_b1[:, None])\n",
    "meta_dam = gmst * (meta_b2[:, None] * gmst + meta_b1[:, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42bc25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "burke_mid_mean = np.mean(burke_mid_dam, axis=0)\n",
    "burke_end_mean = np.mean(burke_end_dam, axis=0)\n",
    "struct_mean = np.mean(struct_dam, axis=0)\n",
    "meta_mean = np.mean(meta_dam, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bd2fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "burke_mid_66 = np.percentile(burke_mid_dam, 66, axis=0)\n",
    "burke_mid_34 = np.percentile(burke_mid_dam, 34, axis=0)\n",
    "burke_mid_95 = np.percentile(burke_mid_dam, 95, axis=0)\n",
    "burke_mid_5 = np.percentile(burke_mid_dam, 5, axis=0)\n",
    "\n",
    "burke_end_66 = np.percentile(burke_end_dam, 66, axis=0)\n",
    "burke_end_34 = np.percentile(burke_end_dam, 34, axis=0)\n",
    "burke_end_95 = np.percentile(burke_end_dam, 95, axis=0)\n",
    "burke_end_5 = np.percentile(burke_end_dam, 5, axis=0)\n",
    "\n",
    "struct_66 = np.percentile(struct_dam, 66, axis=0)\n",
    "struct_34 = np.percentile(struct_dam, 34, axis=0)\n",
    "struct_95 = np.percentile(struct_dam, 95, axis=0)\n",
    "struct_5 = np.percentile(struct_dam, 5, axis=0)\n",
    "\n",
    "meta_66 = np.percentile(meta_dam, 66, axis=0)\n",
    "meta_34 = np.percentile(meta_dam, 34, axis=0)\n",
    "meta_95 = np.percentile(meta_dam, 95, axis=0)\n",
    "meta_5 = np.percentile(meta_dam, 5, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "developed-karen",
   "metadata": {},
   "source": [
    "## Tipping points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pediatric-government",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_data = np.genfromtxt(''.join([path, \"TP_data.csv\"]), delimiter=',')\n",
    "\n",
    "tp_t, tp_d = tp_data.T\n",
    "\n",
    "B_MEAN = 0.48\n",
    "A_MEAN = -0.04\n",
    "\n",
    "CONSUMP_INIT = 61.88 # trillion 2020 USD (from World Bank)\n",
    "GLOB_GDP_INIT = 84.75 # trillion 2020 USD (from World Bank)\n",
    "factor = CONSUMP_INIT/GLOB_GDP_INIT\n",
    "\n",
    "DRAWS = 10**4\n",
    "b_dist = np.random.normal(loc=B_MEAN, scale=0.02, size=DRAWS)\n",
    "a_dist = np.random.normal(loc=A_MEAN, scale=0.01, size=DRAWS)\n",
    "\n",
    "#b_dist = np.random.random(size=DRAWS) * B_MEAN\n",
    "#a_dist = np.random.random(size=DRAWS) * A_MEAN\n",
    "\n",
    "gmst_tp = np.arange(0, 10, 0.01)\n",
    "tp_dam = factor * (b_dist[:, None] * gmst_tp + a_dist[:, None] * gmst_tp**2) * 0.01\n",
    "tp_dam_mean = (B_MEAN * gmst_tp + A_MEAN * gmst_tp**2) * factor * 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anonymous-toilet",
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_66 = np.percentile(tp_dam, 66, axis=0)\n",
    "tp_34 = np.percentile(tp_dam, 34, axis=0)\n",
    "tp_95 = np.percentile(tp_dam, 95, axis=0)\n",
    "tp_5 = np.percentile(tp_dam, 5, axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "humanitarian-borough",
   "metadata": {},
   "source": [
    "# Final figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stock-supply",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.transforms as mtransforms\n",
    "\n",
    "cost_row = ['A', 'B', 'C', 'D']\n",
    "df_row = ['E', 'F', 'G', 'H']\n",
    "\n",
    "fig, ax = plt.subplot_mosaic([cost_row, df_row], sharex=False,\n",
    "                             gridspec_kw={'height_ratios': [1, 1], 'width_ratios': [1, 1, 1, 1]},\n",
    "                            figsize=(16,9))\n",
    "\n",
    "pref_lw = 3.5\n",
    "feat_lw = 2\n",
    "ax['A'].plot(node_times, np.mean(output_obj_list[4].price_path, axis=0), linestyle='solid', \n",
    "             label=\"2% discount rate\", lw = pref_lw)\n",
    "ax['A'].plot(node_times, np.mean(output_obj_list[5].price_path, axis=0), linestyle='dashed', \n",
    "             label=\"1.5% discount rate\", lw = feat_lw)\n",
    "ax['A'].plot(node_times, np.mean(output_obj_list[6].price_path, axis=0), linestyle='dashdot', \n",
    "             label=\"2.5% discount rate\", lw = feat_lw)\n",
    "ax['A'].plot(node_times, np.mean(output_obj_list[7].price_path, axis=0), linestyle='dotted', \n",
    "             label=\"3% discount rate\", lw = feat_lw)\n",
    "ax['A'].set_title(\"Statistical\")\n",
    "ax['A'].set_ylabel(\"Cost ($USD 2020)\")\n",
    "\n",
    "ax['B'].plot(node_times, np.mean(output_obj_list[8].price_path, axis=0), linestyle='solid', \n",
    "             label=\"2% discount rate\", lw = pref_lw)\n",
    "ax['B'].plot(node_times, np.mean(output_obj_list[9].price_path, axis=0), linestyle='dashed', \n",
    "             label=\"1.5% discount rate\", lw = feat_lw)\n",
    "ax['B'].plot(node_times, np.mean(output_obj_list[10].price_path, axis=0), linestyle='dashdot', \n",
    "             label=\"2.5% discount rate\", lw = feat_lw)\n",
    "ax['B'].plot(node_times, np.mean(output_obj_list[11].price_path, axis=0), linestyle='dotted', \n",
    "             label=\"3% discount rate\", lw = feat_lw)\n",
    "ax['B'].set_title(\"Structural\")\n",
    "\n",
    "\n",
    "ax['C'].plot(node_times, np.mean(output_obj_list[12].price_path, axis=0), linestyle='solid', \n",
    "             label=\"2% discount rate\", lw = pref_lw)\n",
    "ax['C'].plot(node_times, np.mean(output_obj_list[13].price_path, axis=0), linestyle='dashed', \n",
    "             label=\"1.5% discount rate\", lw = feat_lw)\n",
    "ax['C'].plot(node_times, np.mean(output_obj_list[14].price_path, axis=0), linestyle='dashdot', \n",
    "             label=\"2.5% discount rate\", lw = feat_lw)\n",
    "ax['C'].plot(node_times, np.mean(output_obj_list[15].price_path, axis=0), linestyle='dotted', \n",
    "             label=\"3% discount rate\", lw = feat_lw)\n",
    "ax['C'].set_title(\"Meta-analytic\")\n",
    "\n",
    "\n",
    "ax['D'].plot(node_times, np.mean(output_obj_list[1].price_path, axis=0), linestyle='dashed', \n",
    "             label=\"1.5% discount rate\", lw = feat_lw, zorder=4, color=color_list[1])\n",
    "ax['D'].plot(node_times, np.mean(output_obj_list[0].price_path, axis=0), linestyle='solid', \n",
    "             label=\"2% discount rate\", lw = pref_lw, color='k')\n",
    "ax['D'].plot(node_times, np.mean(output_obj_list[2].price_path, axis=0), linestyle='dashdot', \n",
    "             label=\"2.5% discount rate\", lw = feat_lw, color=color_list[2])\n",
    "ax['D'].plot(node_times, np.mean(output_obj_list[3].price_path, axis=0), linestyle='dotted', \n",
    "             label=\"3% discount rate\", lw = feat_lw, color=color_list[3])\n",
    "ax['D'].set_title(\"All sampled\")\n",
    "\n",
    "for i in cost_row:\n",
    "    ax[i].set_ylim((0,350))\n",
    "    ax[i].set_xticks([2020,2100,2200])\n",
    "    ax[i].set_xticklabels(['2020', '2100', '2200'])\n",
    "    ax[i].set_xlabel(\"Year\")\n",
    "\n",
    "ax['E'].plot(gmst, 100 * burke_mid_mean, linestyle='solid')\n",
    "ax['E'].plot(gmst, 100 * burke_end_mean, linestyle='dashed', color='k')\n",
    "\n",
    "ax['E'].scatter(burke_2049_ssp2_t, 100 * burke_2049_ssp2_d, alpha=0.5, marker='o', color='k', label='Mid-century')\n",
    "ax['E'].scatter(burke_2099_ssp2_t, 100 * burke_2099_ssp2_d, alpha=0.5, marker='x', color='k', label='End-of-century')\n",
    "\n",
    "ax['E'].fill_between(gmst, 100 * burke_mid_34, 100 * burke_mid_66, alpha=0.4, color=color_list[1])\n",
    "ax['E'].fill_between(gmst, 100 * burke_mid_5, 100 * burke_mid_95, alpha=0.1, color=color_list[2])\n",
    "\n",
    "ax['E'].fill_between(gmst, 100 * burke_end_34, 100 * burke_end_66, alpha=0.4, color=color_list[3])\n",
    "ax['E'].fill_between(gmst, 100 * burke_end_5, 100 * burke_end_95, alpha=0.1, color=color_list[6])\n",
    "ax['E'].set_ylabel(\"Damage (% GDP)\")\n",
    "ax['E'].legend(fontsize=13, loc='upper left')\n",
    "\n",
    "ax['F'].plot(gmst, 100 * struct_mean)\n",
    "ax['F'].scatter(struct_T, 100 * struct_d, alpha=0.5)\n",
    "ax['F'].fill_between(gmst, struct_34 * 100, struct_66 * 100, alpha=0.4, color=color_list[1])\n",
    "ax['F'].fill_between(gmst, struct_5 * 100, struct_95 * 100, alpha=0.1, color=color_list[2])\n",
    "\n",
    "ax['G'].plot(gmst, meta_mean * 100)\n",
    "ax['G'].scatter(hs_T, 100 * hs_d, alpha=0.5)\n",
    "ax['G'].fill_between(gmst, meta_34 * 100, meta_66 * 100, alpha=0.4, color=color_list[1])\n",
    "ax['G'].fill_between(gmst, meta_5 * 100, meta_95 * 100, alpha=0.1, color=color_list[2])\n",
    "\n",
    "ax['H'].plot(gmst_tp, tp_dam_mean * 100)\n",
    "ax['H'].scatter(tp_t, tp_d * 100, s=1.2, alpha=0.004)\n",
    "ax['H'].fill_between(gmst_tp, tp_34 * 100, tp_66 * 100, alpha=0.5, color=color_list[1])\n",
    "ax['H'].fill_between(gmst_tp, tp_5 * 100, tp_95 * 100, alpha=0.3, color=color_list[2])\n",
    "\n",
    "ax['H'].set_xlabel(\"Temperature ($^{\\circ}$C)\")\n",
    "ax['H'].set_xlim((0,10))\n",
    "ax['H'].set_ylim((0,3.5))\n",
    "ax['H'].set_yticks([0,1,2,3])\n",
    "ax['H'].set_xticks([0,5,10])\n",
    "    \n",
    "for j in df_row[:-1]:\n",
    "    ax[j].set_xlim((0,6))\n",
    "    ax[j].set_ylim((0, 55))\n",
    "    ax[j].set_xlabel(\"Temperature ($^{\\circ}$C)\")\n",
    "\n",
    "ax['A'].set_yticks([0,100,200,300])\n",
    "ax['B'].set_yticks([0,100,200,300])\n",
    "ax['C'].set_yticks([0,100,200,300])\n",
    "ax['D'].set_yticks([0,100,200,300])\n",
    "ax['A'].set_ylim((0,320))\n",
    "ax['B'].set_ylim((0,320))\n",
    "ax['C'].set_ylim((0,320))\n",
    "ax['D'].set_ylim((0,320))\n",
    "\n",
    "sns.despine(offset=10, trim=True)\n",
    "ax['D'].legend(loc='center', bbox_to_anchor=(-1.55, -0.355), ncol=5, fontsize=16)\n",
    "fig.subplots_adjust(hspace=0.445, wspace=0.3)\n",
    "\n",
    "\n",
    "# turn off y labels\n",
    "turn_off_ylabels = ['B', 'C', 'D', 'F', 'G']\n",
    "for i in turn_off_ylabels:\n",
    "    ax[i].set_yticklabels([])\n",
    "\n",
    "# label panels\n",
    "for label in cost_row:\n",
    "    # label physical distance in and down:\n",
    "    trans = mtransforms.ScaledTranslation(2.15, 0.1, fig.dpi_scale_trans)\n",
    "    ax[label].text(0.0, 1.0, label, transform=ax[label].transAxes + trans, fontsize=22, fontweight='bold',\n",
    "            verticalalignment='top', bbox=dict(facecolor='1', edgecolor='none', pad=1))\n",
    "    ax[label].tick_params(axis='both', labelsize=16)\n",
    "    \n",
    "for label in df_row:\n",
    "    # label physical distance in and down:\n",
    "    trans = mtransforms.ScaledTranslation(2.15, -0.4, fig.dpi_scale_trans)\n",
    "    ax[label].text(0.0, 1.0, label, transform=ax[label].transAxes + trans, fontsize=22, fontweight='bold',\n",
    "            verticalalignment='top', bbox=dict(facecolor='none', edgecolor='none', pad=1))\n",
    "    ax[label].tick_params(axis='both', labelsize=16)\n",
    "    \n",
    "\n",
    "if save_fig:\n",
    "    fig.savefig(''.join([basefile, 'clim-econ-risk-decomp.png']), bbox_inches='tight', dpi=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15 |Anaconda, Inc.| (default, May  1 2018, 18:37:05) \n[GCC 4.2.1 Compatible Clang 4.0.1 (tags/RELEASE_401/final)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c31d57378e255e91b15dd7240ec366671cfb664d99ccc09907cd926139e0d412"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
